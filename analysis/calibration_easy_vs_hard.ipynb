{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path) as f1:\n",
    "        data = [json.loads(x) for x in f1]\n",
    "    return data\n",
    "\n",
    "paths = [\"../data_subsets/calflow/test/\", \"../data_subsets/treedst/test/\"]\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for dataset, path in zip([\"calflow\", \"treedst\"], paths):\n",
    "    easy_data = read_json(path + \"easy.jsonl\")\n",
    "    hard_data = read_json(path + \"hard.jsonl\")\n",
    "    all_data[dataset] = (easy_data, hard_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factors making examples easy and hard\n",
    "Which factors make an example easy or hard? We will look at 3 factors:\n",
    "- length (numer of tokens)\n",
    "- number of sentences \n",
    "- percentage of value op values that are present in the source \n",
    "\n",
    "## Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'calflow': {'easy': '7.59', 'hard': '11.15'}, 'treedst': {'easy': '8.41', 'hard': '8.16'}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np \n",
    "# get input length\n",
    "\n",
    "lengths_by_dataset_and_split = {\"calflow\": {\"easy\": [], \"hard\": []}, \"treedst\": {\"easy\": [], \"hard\": []}}\n",
    "\n",
    "for dataset, (easy_data, hard_data) in all_data.items():\n",
    "    for split, data in zip([\"easy\", \"hard\"], [easy_data, hard_data]):\n",
    "        for example in data:\n",
    "            split_input = re.split(\"\\s+\", example['user_turn_1']) \n",
    "            lengths_by_dataset_and_split[dataset][split].append(len(split_input))\n",
    "\n",
    "\n",
    "mean_lengths_by_dataset_and_split = {\"calflow\": {\"easy\": [], \"hard\": []}, \"treedst\": {\"easy\": [], \"hard\": []}}\n",
    "for dataset, split_data in lengths_by_dataset_and_split.items():\n",
    "    for split, lengths in split_data.items():\n",
    "        mean_lengths_by_dataset_and_split[dataset][split] = f\"{np.mean(lengths):.2f}\"\n",
    "print(mean_lengths_by_dataset_and_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.09114175414813 30.63461998039481\n",
      "calflow: t=-33.93127248220638, p=5.938992721630618e-228\n",
      "28.23033486966547 25.29030477620862\n",
      "treedst: t=2.5430596212422185, p=0.011022906908403442\n"
     ]
    }
   ],
   "source": [
    "# for a given dataset, is there a significant difference in input length between easy and hard examples?\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "for dataset, split_data in lengths_by_dataset_and_split.items():\n",
    "    easy_lengths = split_data[\"easy\"]\n",
    "    hard_lengths = split_data[\"hard\"]\n",
    "    var_easy = np.var(easy_lengths)\n",
    "    var_hard = np.var(hard_lengths)\n",
    "    print(var_easy, var_hard)\n",
    "    t, p = ttest_ind(easy_lengths, hard_lengths, equal_var=False)\n",
    "    print(f\"{dataset}: t={t}, p={p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of examples with multiple sentences\n",
    "For each dataset, what percentage of examples have more than one sentence (as measured by the presence of a period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'calflow': {'easy': '3.94', 'hard': '9.17'}, 'treedst': {'easy': '8.14', 'hard': '10.40'}}\n"
     ]
    }
   ],
   "source": [
    "multi_sentence_by_dataset_and_split = {\"calflow\": {\"easy\": [], \"hard\": []}, \"treedst\": {\"easy\": [], \"hard\": []}}\n",
    "for dataset, (easy_data, hard_data) in all_data.items():\n",
    "    for split, data in zip([\"easy\", \"hard\"], [easy_data, hard_data]):\n",
    "        for example in data:\n",
    "            split_input = re.split(\"\\s+\", example['user_turn_1']) \n",
    "            if split_input[-1] == \".\":\n",
    "                split_input = split_input[0:-1]\n",
    "            if \".\" in split_input: \n",
    "                period_index = split_input.index(\".\")\n",
    "                try:\n",
    "                    before, after = split_input[period_index-1], split_input[period_index+1]\n",
    "                    # check if they're numbers \n",
    "                    if before.isdigit() and after.isdigit():\n",
    "                        continue\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                multi_sentence_by_dataset_and_split[dataset][split].append(1)\n",
    "            else:\n",
    "                multi_sentence_by_dataset_and_split[dataset][split].append(0)\n",
    "\n",
    "mean_multi_sentence_by_dataset_and_split = {\"calflow\": {\"easy\": [], \"hard\": []}, \"treedst\": {\"easy\": [], \"hard\": []}}\n",
    "for dataset, split_data in multi_sentence_by_dataset_and_split.items():\n",
    "    for split, multi_sentence in split_data.items():\n",
    "        mean_multi_sentence_by_dataset_and_split[dataset][split] = f\"{np.mean(multi_sentence)*100:.2f}\"\n",
    "    \n",
    "print(mean_multi_sentence_by_dataset_and_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0378743795207357 0.0832977853331169\n",
      "calflow: t=-9.84574638735878, p=1.2072188519653565e-22\n",
      "0.07479783768427546 0.09315387494003685\n",
      "treedst: t=-3.9028321965146415, p=9.663557443221441e-05\n"
     ]
    }
   ],
   "source": [
    "# check for significance \n",
    "\n",
    "for dataset, split_data in multi_sentence_by_dataset_and_split.items():\n",
    "    easy_lengths = split_data[\"easy\"]\n",
    "    hard_lengths = split_data[\"hard\"]\n",
    "    var_easy = np.var(easy_lengths)\n",
    "    var_hard = np.var(hard_lengths)\n",
    "    print(var_easy, var_hard)\n",
    "    t, p = ttest_ind(easy_lengths, hard_lengths, equal_var=False)\n",
    "    print(f\"{dataset}: t={t}, p={p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying\n",
    "For TreeDST, it seems like a lot of hard examples are based on not having access to enough context.\n",
    "We will see what percentage of values_op values we can copy from the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'calflow': {'easy': 0.4718745906578292, 'hard': 0.5057958477508651}, 'treedst': {'easy': 0.5708790772693385, 'hard': 0.38384341199606686}}\n"
     ]
    }
   ],
   "source": [
    "## get set of value ops \n",
    "from dataflow.core.lispress import parse_lispress, lispress_to_program\n",
    "from dataflow.core.program import ValueOp\n",
    "def get_value_ops(lispress):\n",
    "    all_values = []\n",
    "    lispress = parse_lispress(lispress)\n",
    "    program, __ = lispress_to_program(lispress, 0)\n",
    "    for expression in program.expressions:\n",
    "        if isinstance(expression.op, ValueOp):\n",
    "            underlying = str(json.loads(expression.op.value)['underlying']).strip()\n",
    "            all_values.append(underlying.lower())\n",
    "    return all_values \n",
    "\n",
    "value_ops_in_src_by_dataset_and_split = {\"calflow\": {\"easy\": [], \"hard\": []}, \"treedst\": {\"easy\": [], \"hard\": []}}\n",
    "for dataset, (easy_data, hard_data) in all_data.items():\n",
    "    for split, data in zip([\"easy\", \"hard\"], [easy_data, hard_data]):\n",
    "        for example in data:\n",
    "            value_ops = get_value_ops(example['tgt'])\n",
    "            input = \" __BLAH__ \".join([str(example['user_turn_0']), str(example['agent_turn_0']), example['user_turn_1']])\n",
    "            split_input = re.split(\"\\s+\", input) \n",
    "            split_input = [x.lower().strip() for x in split_input]\n",
    "            # get percentage of value ops in input \n",
    "            in_input, total = 0, 0\n",
    "            for v in value_ops:\n",
    "                if v in split_input:\n",
    "                    in_input += 1\n",
    "                total += 1\n",
    "            if total > 0:\n",
    "                value_ops_in_src_by_dataset_and_split[dataset][split].append(in_input / total)\n",
    "\n",
    "mean_value_ops_in_src_by_dataset_and_split = {\"calflow\": {\"easy\": [], \"hard\": []}, \"treedst\": {\"easy\": [], \"hard\": []}}\n",
    "for dataset, split_data in value_ops_in_src_by_dataset_and_split.items():\n",
    "    for split, value_ops in split_data.items():\n",
    "        mean_value_ops_in_src_by_dataset_and_split[dataset][split] = np.mean(value_ops)\n",
    "\n",
    "print(mean_value_ops_in_src_by_dataset_and_split)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for significance \n",
    "\n",
    "for dataset, split_data in value_ops_in_src_by_dataset_and_split.items():\n",
    "    easy_lengths = split_data[\"easy\"]\n",
    "    hard_lengths = split_data[\"hard\"]\n",
    "    var_easy = np.var(easy_lengths)\n",
    "    var_hard = np.var(hard_lengths)\n",
    "    print(var_easy, var_hard)\n",
    "    t, p = ttest_ind(easy_lengths, hard_lengths, equal_var=False)\n",
    "    print(f\"{dataset}: t={t}, p={p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('miso_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9db1c0e1c59df8b57e6ccdbb7c3746bf45f553f1d28626d748c067e213df640a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
